/**
 * WARNING: This file is automatically generated.
 * DO NOT EDIT THIS FILE DIRECTLY.
 * Any changes should be made to the generation scripts instead.
 */

import { z } from "zod";
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import * as api from "./api-client.js";

export function registerGeneratedRoutes(server: McpServer) {
  // Register 1-chat endpoint
  server.tool(
    "1-chat",
    "POST /1/chat",
    {
      model: z.string().default("llama-3"),
      messages: z.array(z.object({ 
                role: z.enum(["user", "assistant", "system"]), 
                content: z.string() 
              })),
      temperature: z.number().default(0.1),
      max_tokens: z.number().default(500),
      top_p: z.number().default(1),
      stream: z.boolean().default(true),
      logprobs: z.boolean().default(false)
    },
    async (params) => {
      try {
        const response = await api.subnet_1_chat(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "1-chat";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 4-completions endpoint
  server.tool(
    "4-completions",
    "POST /4/completions",
    {
      model: z.enum(["deepseek-ai/DeepSeek-R1", "deepseek-ai/DeepSeek-V3"]).default("deepseek-ai/DeepSeek-R1").describe("The model to use for completion."),
      prompt: z.string().default("").describe("Text to generate completion for."),
      temperature: z.number().default(0.7).describe("Controls randomness in the response. Lower is more deterministic."),
      max_tokens: z.number().default(256).describe("Maximum number of tokens to generate."),
      top_p: z.number().default(0.1).describe("Controls diversity via nucleus sampling."),
      frequency_penalty: z.number().default(0).describe("Reduces repetition of token sequences."),
      presence_penalty: z.number().default(0).describe("Reduces repetition of topics."),
      stream: z.boolean().default(true).describe("Whether to stream the response."),
      logprobs: z.boolean().default(false).describe("Whether to return log probabilities of the output tokens.")
    },
    async (params) => {
      try {
        const response = await api.subnet_4_completions(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "4-completions";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 4-chat endpoint
  server.tool(
    "4-chat",
    "POST /4/chat",
    {
      model: z.enum(["deepseek-ai/DeepSeek-R1", "deepseek-ai/DeepSeek-V3"]).default("deepseek-ai/DeepSeek-R1").describe("The model to use for chat completion."),
      messages: z.array(z.object({ 
                role: z.enum(["user", "assistant", "system"]), 
                content: z.string() 
              })),
      temperature: z.number().default(0.7).describe("Controls randomness in the response. Lower is more deterministic."),
      max_tokens: z.number().default(256).describe("Maximum number of tokens to generate."),
      top_p: z.number().default(0.1).describe("Controls diversity via nucleus sampling."),
      frequency_penalty: z.number().default(0).describe("Reduces repetition of token sequences."),
      presence_penalty: z.number().default(0).describe("Reduces repetition of topics."),
      stream: z.boolean().default(true).describe("Whether to stream the response."),
      logprobs: z.boolean().default(false).describe("Whether to return log probabilities of the output tokens.")
    },
    async (params) => {
      try {
        const response = await api.subnet_4_chat(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "4-chat";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 19-chat-completions endpoint
  server.tool(
    "19-chat-completions",
    "POST /19/chat/completions",
    {
      messages: z.array(z.object({ 
                role: z.enum(["user", "assistant", "system"]), 
                content: z.string() 
              })),
      temperature: z.number().default(0.5).describe("Temperature for text generation"),
      max_tokens: z.number().default(500).describe("Max tokens for text generation"),
      model: z.string().default(""),
      top_p: z.number().default(0.5).describe("Top P for text generation"),
      stream: z.boolean().default(false).describe("Stream for text generation")
    },
    async (params) => {
      try {
        const response = await api.subnet_19_chat_completions(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "19-chat-completions";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 19-completions endpoint
  server.tool(
    "19-completions",
    "POST /19/completions",
    {
      prompt: z.string().default(""),
      temperature: z.number().default(0.5).describe("Temperature for text generation"),
      max_tokens: z.number().default(50).describe("Max tokens for text generation"),
      model: z.string().default(""),
      top_p: z.number().default(0.5).describe("Top P for text generation"),
      stream: z.boolean().default(false).describe("Stream for text generation")
    },
    async (params) => {
      try {
        const response = await api.subnet_19_completions(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "19-completions";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 19-text-to-image endpoint
  server.tool(
    "19-text-to-image",
    "POST /19/text-to-image",
    {
      prompt: z.string().default("").describe("Prompt for image generation"),
      negative_prompt: z.string().default("").describe("Negative prompt for image generation"),
      steps: z.number().default(8).describe("Number of inference steps, higher for more quality but increased generation time"),
      cfg_scale: z.number().default(3).describe("Guidance scale"),
      width: z.number().default(1024).describe("Width for image generation"),
      height: z.number().default(1024).describe("Height for image generation"),
      model: z.string().default("")
    },
    async (params) => {
      try {
        const response = await api.subnet_19_text_to_image(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "19-text-to-image";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 19-image-to-image endpoint
  server.tool(
    "19-image-to-image",
    "POST /19/image-to-image",
    {
      init_image: z.string().default("").describe("URL for image"),
      prompt: z.string().default(""),
      negative_prompt: z.string().default("").describe("Negative prompt for image generation"),
      steps: z.number().default(10).describe("Number of inference steps, higher for more quality but increased generation time"),
      cfg_scale: z.number().default(3).describe("Guidance scale"),
      width: z.number().default(1024).describe("Width for image generation"),
      height: z.number().default(1024).describe("Height for image generation"),
      model: z.string().default(""),
      image_strength: z.number().default(0.5).describe("Image strength of the generated image with respect to the original image")
    },
    async (params) => {
      try {
        const response = await api.subnet_19_image_to_image(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "19-image-to-image";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 19-avatar endpoint
  server.tool(
    "19-avatar",
    "POST /19/avatar",
    {
      prompt: z.string().default("").describe("Prompt for avatar generation"),
      negative_prompt: z.string().default("").describe("Negative prompt for avatar generation"),
      steps: z.number().default(10).describe("Steps for avatar generation"),
      cfg_scale: z.number().default(3).describe("CFG scale for avatar generation"),
      width: z.number().default(1024).describe("Width for avatar generation"),
      height: z.number().default(1024).describe("Height for avatar generation"),
      ipadapter_strength: z.number().default(0.5).describe("Image Adapter Strength for avatar generation"),
      control_strength: z.number().default(0.5).describe("Control Strength for avatar generation"),
      init_image: z.string().default("").describe("URL for image")
    },
    async (params) => {
      try {
        const response = await api.subnet_19_avatar(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "19-avatar";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 20-chat endpoint
  server.tool(
    "20-chat",
    "POST /20/chat",
    {
      messages: z.array(z.object({ 
                role: z.enum(["user", "assistant", "system"]), 
                content: z.string() 
              })).describe("Chat message history"),
      tools: z.array(z.object({ name: z.string(), description: z.string(), arguments: z.object({  }) })).describe("List of tools available for the model to use")
    },
    async (params) => {
      try {
        const response = await api.subnet_20_chat(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "20-chat";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 22-search endpoint
  server.tool(
    "22-search",
    "POST /22/search",
    {
      prompt: z.string().default("").describe("Search query text to run tools with"),
      tools: z.array(z.string()).describe("List of search tools to use for fetching data"),
      model: z.enum(["NOVA", "ORBIT", "HORIZON"]).default("NOVA").describe("Model to use for scraping"),
      date_filter: z.enum(["PAST_24_HOURS", "PAST_2_DAYS", "PAST_WEEK", "PAST_2_WEEKS", "PAST_MONTH", "PAST_2_MONTHS", "PAST_YEAR", "PAST_2_YEARS"]).default("PAST_WEEK").describe("Time range filter for results"),
      streaming: z.boolean().default(true).describe("Whether to stream results"),
      result_type: z.enum(["ONLY_LINKS", "LINKS_WITH_SUMMARIES", "LINKS_WITH_FINAL_SUMMARY"]).default("LINKS_WITH_FINAL_SUMMARY").describe("The result type for the search"),
      system_message: z.string().default("").describe("Custom system message to be used for the search")
    },
    async (params) => {
      try {
        const response = await api.subnet_22_search(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "22-search";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 22-search-links-web endpoint
  server.tool(
    "22-search-links-web",
    "POST /22/search/links/web",
    {
      prompt: z.string().default("").describe("Search query prompt"),
      tools: z.array(z.string()).describe("List of tools to search with"),
      model: z.enum(["NOVA", "ORBIT", "HORIZON"]).default("NOVA").describe("Model to use for scraping")
    },
    async (params) => {
      try {
        const response = await api.subnet_22_search_links_web(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "22-search-links-web";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 22-search-links-twitter endpoint
  server.tool(
    "22-search-links-twitter",
    "POST /22/search/links/twitter",
    {
      prompt: z.string().default("").describe("Search query prompt"),
      model: z.enum(["NOVA", "ORBIT", "HORIZON"]).default("NOVA").describe("Model to use for scraping")
    },
    async (params) => {
      try {
        const response = await api.subnet_22_search_links_twitter(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "22-search-links-twitter";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 32-detect-text endpoint
  server.tool(
    "32-detect-text",
    "POST /32/detect-text",
    {
      text: z.string().default("").describe("The text to be analyzed for AI-generated content."),
      deep_scan: z.boolean().default(false)
    },
    async (params) => {
      try {
        const response = await api.subnet_32_detect_text(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "32-detect-text";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 34-detect-image endpoint
  server.tool(
    "34-detect-image",
    "POST /34/detect-image",
    {
      image: z.string().default("").describe("URL or Base64 encoded image. - For URLs: The image must be publicly accessible. - For Base64: The max size is 4MB. Supported MIME types: image/gif, image/jpeg, image/png, image/bmp, image/tiff.\n")
    },
    async (params) => {
      try {
        const response = await api.subnet_34_detect_image(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "34-detect-image";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 34-detect-video endpoint
  server.tool(
    "34-detect-video",
    "POST /34/detect-video",
    {

    },
    async (params) => {
      try {
        const response = await api.subnet_34_detect_video(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "34-detect-video";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 47-compress-text endpoint
  server.tool(
    "47-compress-text",
    "POST /47/compress/text",
    {
      text: z.string().default("In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector.").describe("Text to be compressed"),
      top_node_performance: z.number().default(0.1).describe("Performance parameter for compression")
    },
    async (params) => {
      try {
        const response = await api.subnet_47_compress_text(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "47-compress-text";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 47-compress-messages endpoint
  server.tool(
    "47-compress-messages",
    "POST /47/compress/messages",
    {
      messages: z.array(z.object({ 
                role: z.enum(["user", "assistant", "system"]), 
                content: z.string() 
              })).describe("List of messages where each message has a 'role' and 'content' key."),
      compress_user: z.boolean().default(true).describe("Whether to compress user messages"),
      compress_assistant: z.boolean().default(true).describe("Whether to compress assistant messages"),
      top_node_performance: z.number().default(0.1).describe("Performance parameter for compression")
    },
    async (params) => {
      try {
        const response = await api.subnet_47_compress_messages(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "47-compress-messages";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 64-chat-completions endpoint
  server.tool(
    "64-chat-completions",
    "POST /64/chat/completions",
    {
      model: z.enum(["deepseek-ai/DeepSeek-V3-0324", "chutesai/Mistral-Small-3.1-24B-Instruct-2503", "deepseek-ai/DeepSeek-R1", "chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8", "deepseek-ai/DeepSeek-V3", "Qwen/Qwen2.5-VL-32B-Instruct", "deepseek-ai/DeepSeek-R1-Zero", "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1", "chutesai/Llama-4-Scout-17B-16E-Instruct", "deepseek-ai/DeepSeek-V3-Base", "moonshotai/Kimi-VL-A3B-Thinking", "nvidia/Llama-3_3-Nemotron-Super-49B-v1", "unsloth/gemma-3-12b-it", "unsloth/gemma-3-1b-it", "unsloth/gemma-3-4b-it", "cognitivecomputations/Dolphin3.0-Mistral-24B", "nvidia/Llama-3.1-Nemotron-Nano-8B-v1", "NousResearch/DeepHermes-3-Llama-3-8B-Preview", "cognitivecomputations/Dolphin3.0-R1-Mistral-24B", "RekaAI/reka-flash-3", "open-r1/OlympicCoder-32B", "open-r1/OlympicCoder-7B"]).default("deepseek-ai/DeepSeek-V3-0324").describe("The model to use for chat completion."),
      messages: z.array(z.object({ 
                role: z.enum(["user", "assistant", "system"]), 
                content: z.string() 
              })),
      temperature: z.number().default(0.7).describe("Controls randomness in the response. Lower is more deterministic."),
      max_tokens: z.number().default(1024).describe("Maximum number of tokens to generate."),
      top_p: z.number().default(1).describe("Controls diversity via nucleus sampling."),
      stream: z.boolean().default(true).describe("Whether to stream the response."),
      seed: z.number().default(0).describe("Seed for deterministic generation. Defaults to random if not provided."),
      stop: z.string().describe("Sequence where the API will stop generating tokens."),
      logprobs: z.boolean().default(false).describe("Whether to return log probabilities of the output tokens.")
    },
    async (params) => {
      try {
        const response = await api.subnet_64_chat_completions(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "64-chat-completions";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );

  // Register 64-completions endpoint
  server.tool(
    "64-completions",
    "POST /64/completions",
    {
      model: z.enum(["deepseek-ai/DeepSeek-V3-0324", "chutesai/Mistral-Small-3.1-24B-Instruct-2503", "deepseek-ai/DeepSeek-R1", "chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8", "deepseek-ai/DeepSeek-V3", "Qwen/Qwen2.5-VL-32B-Instruct", "deepseek-ai/DeepSeek-R1-Zero", "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1", "chutesai/Llama-4-Scout-17B-16E-Instruct", "deepseek-ai/DeepSeek-V3-Base", "moonshotai/Kimi-VL-A3B-Thinking", "nvidia/Llama-3_3-Nemotron-Super-49B-v1", "unsloth/gemma-3-12b-it", "unsloth/gemma-3-1b-it", "unsloth/gemma-3-4b-it", "cognitivecomputations/Dolphin3.0-Mistral-24B", "nvidia/Llama-3.1-Nemotron-Nano-8B-v1", "NousResearch/DeepHermes-3-Llama-3-8B-Preview", "cognitivecomputations/Dolphin3.0-R1-Mistral-24B", "RekaAI/reka-flash-3", "open-r1/OlympicCoder-32B", "open-r1/OlympicCoder-7B"]).default("deepseek-ai/DeepSeek-V3-0324").describe("The model to use for completion."),
      prompt: z.string().default("").describe("Text to generate completion for."),
      temperature: z.number().default(0.7).describe("Controls randomness in the response. Lower is more deterministic."),
      max_tokens: z.number().default(1024).describe("Maximum number of tokens to generate."),
      top_p: z.number().default(1).describe("Controls diversity via nucleus sampling."),
      stream: z.boolean().default(true).describe("Whether to stream the response."),
      seed: z.number().default(0).describe("Seed for deterministic generation. Defaults to random if not provided."),
      stop: z.string().describe("Sequence where the API will stop generating tokens."),
      logprobs: z.boolean().default(false).describe("Whether to return log probabilities of the output tokens.")
    },
    async (params) => {
      try {
        const response = await api.subnet_64_completions(params);
        
        // Check if response contains image data
        if (response && typeof response === 'object' && response.image_b64) {
          // Determine the appropriate MIME type based on the endpoint
          let mimeType = "image/png"; // Default
          const operationId = "64-completions";
          if (operationId.includes("text-to-image")) {
            mimeType = "image/png";
          } else if (operationId.includes("image-to-image")) {
            mimeType = "image/jpeg";
          } else if (operationId.includes("avatar")) {
            mimeType = "image/png";
          }
          
          // Create a proper resource URI following the MCP specification
          const resourceUri = `bittensor://${operationId}/image`;
          
          const result = {
            content: [
              {
                type: "resource" as const,
                resource: {
                  uri: resourceUri,
                  mimeType: mimeType,
                  blob: response.image_b64
                }
              }
            ]
          };
          
          return result;
        }
        
        // Default text response handling
        return {
          content: [
            {
              type: "text",
              text: typeof response === "string" 
                ? response 
                : (response && typeof response === "object" 
                  ? JSON.stringify(response, null, 2) 
                  : String(response)),
            },
          ],
        };
      } catch (error: any) {
        return {
          content: [
            {
              type: "text",
              text: `Error: ${error?.message || "Unknown error occurred"}`,
            },
          ],
          isError: true,
        };
      }
    }
  );
}
